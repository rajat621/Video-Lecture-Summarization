ğŸ¥ Video & Lecture Summarization

An AI-powered video and lecture summarization pipeline built in a Google Colab environment.
This project automatically converts long lecture or informational videos into concise, structured summaries using speech recognition and transformer-based NLP models.

âœ¨ Features

Automatic Audio Extraction â€“ Extracts audio track from input video files using MoviePy/FFmpeg.

Speech-to-Text Conversion â€“ Transcribes spoken content into text using Whisper (ASR model).

Abstractive Text Summarization â€“ Generates coherent summaries using transformer models like BART/T5.

Long Video Handling â€“ Processes lengthy lectures by chunking transcripts before summarization.

Cloud Execution (Colab) â€“ GPU-enabled processing without requiring high-end local hardware.

Exportable Summaries â€“ Saves generated summaries as text files for later use.

ğŸ“¦ Installation (Google Colab)

Run the following in a Colab cell:

pip install -q torch transformers sentencepiece
pip install -q moviepy openai-whisper ffmpeg-python
pip install -q numpy pandas matplotlib


If using GPU in Colab:

Runtime â†’ Change runtime type â†’ GPU

ğŸš€ Usage

1ï¸âƒ£ Upload your lecture/video file in Colab

2ï¸âƒ£ Run the pipeline cells sequentially

3ï¸âƒ£ The system will:

Extract audio

Convert speech to text

Generate summary

4ï¸âƒ£ The final summary will be displayed and saved

ğŸ›  How It Works

Video Input â€“ User provides a lecture or educational video.

Audio Extraction â€“ Audio is separated from video using MoviePy/FFmpeg.

Speech Recognition â€“ Whisper model converts audio into transcript text.

Text Processing â€“ Transcript is cleaned and formatted.

Summarization â€“ BART/T5 model generates an abstractive summary.

Output â€“ Final summarized text is displayed and stored.

âš™ Configuration

You can modify parameters inside the configuration cell:

MAX_INPUT_LENGTH = 1024      # Token length per chunk
MAX_SUMMARY_LENGTH = 150     # Summary size
MIN_SUMMARY_LENGTH = 50
MODEL_NAME = "facebook/bart-large-cnn"


For Whisper:

WHISPER_MODEL = "base"   # tiny / base / small / medium / large

ğŸ§  Technologies Used

Python

PyTorch

Hugging Face Transformers

OpenAI Whisper

MoviePy / FFmpeg

NumPy / Pandas

Google Colab (GPU runtime)

ğŸ¯ Capabilities

Summarizes long lecture videos

Reduces 1-hour lecture into short readable summary

Produces natural language (abstractive) summaries

Works entirely in cloud-based environment

Easily extendable to multilingual support

ğŸ“œ License

This project is intended for educational and research purposes.
Please follow the respective licenses of:

Whisper

Hugging Face Transformers

BART / T5 models
